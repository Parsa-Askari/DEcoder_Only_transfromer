{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries import PreprocessDailydialog , PreprocessEmpathy , processs ,read_tokenized_data ,dataset\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "empathy_path=\"./data/empatheticdialogues/\"\n",
    "daily_path=\"./data/dailydialog/\"\n",
    "out_empathy_path=\"./data/empatheticdialogues/processed/\"\n",
    "out_daily_path=\"./data/dailydialog/processed/\"\n",
    "combine_path=\"./data/full/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 84169/84169 [00:00<00:00, 798068\n",
      "100%|█| 10973/10973 [00:00<00:00, 198763\n",
      "100%|█| 12078/12078 [00:00<00:00, 221742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 84169/84169 [00:17<00:00, 4714.7\n",
      "100%|█| 10973/10973 [00:02<00:00, 4715.5\n",
      "100%|█| 12078/12078 [00:02<00:00, 4710.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the data to ./data/empatheticdialogues/processed/\n"
     ]
    }
   ],
   "source": [
    "pre1=PreprocessEmpathy(empathy_path,out_empathy_path)\n",
    "pre1.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 11118/11118 [00:00<00:00, 285973\n",
      "100%|█| 1000/1000 [00:00<00:00, 288605.5\n",
      "100%|█| 1000/1000 [00:00<00:00, 277915.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 87170/87170 [00:18<00:00, 4613.1\n",
      "100%|█| 7740/7740 [00:01<00:00, 4576.77i\n",
      "100%|█| 8069/8069 [00:01<00:00, 4688.70i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the data to ./data/dailydialog/processed/\n"
     ]
    }
   ],
   "source": [
    "pre2=PreprocessDailydialog(daily_path,out_daily_path)\n",
    "pre2.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "empathy_train=os.path.join(out_empathy_path,\"train.csv\")\n",
    "empathy_test=os.path.join(out_empathy_path,\"test.csv\")\n",
    "empathy_valid=os.path.join(out_empathy_path,\"valid.csv\")\n",
    "\n",
    "daily_train=os.path.join(out_daily_path,\"train.csv\")\n",
    "daily_test=os.path.join(out_daily_path,\"test.csv\")\n",
    "daily_valid=os.path.join(out_daily_path,\"valid.csv\")\n",
    "\n",
    "train_df=pd.concat([pd.read_csv(empathy_train),pd.read_csv(daily_train)],axis=0)\n",
    "valid_df=pd.concat([pd.read_csv(empathy_valid),pd.read_csv(daily_valid)],axis=0)\n",
    "test_df=pd.concat([pd.read_csv(empathy_test),pd.read_csv(daily_test)],axis=0)\n",
    "train_df.to_csv(os.path.join(combine_path,\"train.csv\"),index=False)\n",
    "valid_df.to_csv(os.path.join(combine_path,\"valid.csv\"),index=False)\n",
    "test_df.to_csv(os.path.join(combine_path,\"test.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createing vocab and transfroming train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 171259/171259 [00:43<00:00, 3940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max size :  288\n",
      "transforming valid and test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 20141/20141 [00:05<00:00, 3657.0\n",
      "100%|█| 18698/18698 [00:04<00:00, 3777.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turning token to index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 171259/171259 [00:01<00:00, 1107\n",
      "100%|█| 20141/20141 [00:00<00:00, 94758.\n",
      "100%|█| 18698/18698 [00:00<00:00, 94837.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the data in ./data/tokenized/\n",
      "clear memory\n"
     ]
    }
   ],
   "source": [
    "p=processs()\n",
    "p.standard_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import libraries.data\n",
    "import libraries.preprocess\n",
    "importlib.reload(libraries.data)\n",
    "importlib.reload(libraries.preprocess)\n",
    "\n",
    "\n",
    "from libraries.data import *\n",
    "from libraries.preprocess import *\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,valid,test,vocab,Index,PAD,EOS,SOS,UKN,max_size=read_tokenized_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl=partial(collect_fn, pad=Index[PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl=DataLoader(ds,batch_size=32,collate_fn=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co=0\n",
    "for x,y in dl:\n",
    "    print(x.shape,y.shape)\n",
    "    if(co==2):\n",
    "        break\n",
    "    co+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PositionalEncoding(4,4,n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=torch.zeros(32,1)\n",
    "l2=torch.zeros(32,256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[torch.rand(32,1),torch.rand(32,1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=0\n",
    "attentions=torch.unsqueeze(torch.rand(32,3),dim=-1)\n",
    "value=torch.rand(32,256)\n",
    "for i in range(attentions.shape[1]):\n",
    "    l+=value*attentions[:,i]\n",
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=torch.tensor([[3,4,0,1],[2,1,3,0]])\n",
    "emb=torch.nn.Embedding(num_embeddings=5,embedding_dim=10)\n",
    "l=emb(ls)\n",
    "l[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.reshape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
